{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic lemmatization and stemming using spacy and NLTk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('running', 'VBG'), ('painting', 'VBG'), ('walking', 'VBG'), ('dressing', 'VBG'), ('likely', 'JJ'), ('children', 'NNS'), ('whom', 'WP'), ('good', 'JJ'), ('ate', 'NN'), ('fishing', 'NN')]\n",
      "run\n",
      "paint\n",
      "walk\n",
      "dress\n",
      "like\n",
      "children\n",
      "whom\n",
      "good\n",
      "ate\n",
      "fish\n"
     ]
    }
   ],
   "source": [
    "stem = PorterStemmer()\n",
    "words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']\n",
    "print(nltk.pos_tag(words))\n",
    "for word in words:\n",
    "    print(stem.stem(word))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run|VBG\n",
      "paint|VBG\n",
      "walk|VBG\n",
      "dress|VBG\n",
      "likely|JJ\n",
      "child|NNS\n",
      "who|WP\n",
      "good|JJ\n",
      "eat|VBD\n",
      "fishing|NN\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('running painting walking dressing likely children who good ate fishing')\n",
    "# print(doc.is_tagged)\n",
    "for token in doc:\n",
    "    print(token.lemma_ + \" | \" + token.tag_)\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text lemmatization using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latha be very multi talented girl . she be good at many skill like dancing , running , singing , play . she also like eat Pav Bhagi . she have a \n",
      " habit of fishing and swim too . besides all this , she be a wonderful at cook too . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp= spacy.load('en_core_web_sm')\n",
    "doc = nlp(text=text)\n",
    "list1 = [token.lemma_ for token in doc]\n",
    "sent = ' '.join(list1)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text stemming using ntlk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latha is veri multi talent girl.sh is good at mani skill like danc , run , sing , playing.sh also like eat pav bhagi . she ha a habit of fish and swim too.besid all thi , she is a wonder at cook too .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "list2 = [ i for i in word_tokenize(text)]\n",
    "stem= PorterStemmer()\n",
    "list3 = [stem.stem(token) for token in list2]\n",
    "sentence1 = \" \".join(list3)\n",
    "print(sentence1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text lemmatization using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latha is very multi talented girl.She is good at many skill like dancing , running , singing , playing.She also like eating Pav Bhagi . she ha a habit of fishing and swimming too.Besides all this , she is a wonderful at cooking too .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "list4 = [lemma.lemmatize(token) for token in list2]\n",
    "sentence2 = \" \".join(list4)\n",
    "print(sentence2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
